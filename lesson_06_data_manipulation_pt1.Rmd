---
title: "Manipulating and analyzing data in the tidyverse, Part 1"
---


<div class = "blue">

### Learning Objectives

* Describe the purpose of the **`dplyr`** and **`tidyr`** packages.
* Select certain columns in a data frame with the **`dplyr`** function `select`.
* Select certain rows in a data frame according to filtering conditions with the **`dplyr`** function `filter`.
* Link the output of one **`dplyr`** function to the input of another function with the 'pipe' operator `%>%`.
* Add new columns to a data frame that are functions of existing columns with `mutate`.
* Use the split-apply-combine concept for data analysis.
* Use `summarize`, `group_by`, and `tally` to split a data frame into groups of observations, apply a summary statistics for each group, and then combine the results.

</div>

## Data Manipulation using **`dplyr`** and **`tidyr`**

Bracket subsetting is handy, but it can be cumbersome and difficult to read,
especially for complicated operations. Enter **`dplyr`**. **`dplyr`** is a package for
making tabular data manipulation easier. It pairs nicely with **`tidyr`** which enables you to swiftly convert between different data formats for plotting and analysis.

Packages in R are basically sets of additional functions that let you do more
stuff. The functions we've been using so far, like `str()` or `data.frame()`,
come built into R; packages give you access to more of them. Before you use a
package for the first time you need to install it on your machine, and then you
should import it in every subsequent R session when you need it. You should
already have installed the **`tidyverse`** package. This is an
"umbrella-package" that installs several packages useful for data analysis which
work together well such as **`tidyr`**, **`dplyr`**, **`ggplot2`**, **`tibble`**, etc.

The **`tidyverse`** package tries to address 3 major problems with some of base R functions:
1. The results from a base R function sometimes depend on the type of data.
2. Using R expressions in a non standard way, which can be confusing for new learners.
3. Hidden arguments, having default operations that new learners are not aware of.

To load the package type:


```{r, message = FALSE, purl = FALSE, warning = FALSE}
library("tidyverse")    ## load the tidyverse packages, incl. dplyr
```

### What are **`dplyr`** and **`tidyr`**?

The package **`dplyr`** provides easy tools for the most common data manipulation
tasks. It is built to work directly with data frames, with many common tasks
optimized by being written in a compiled language (C++). An additional feature is the
ability to work directly with data stored in an external database. The benefits of
doing this are that the data can be managed natively in a relational database,
queries can be conducted on that database, and only the results of the query are
returned.

This addresses a common problem with R in that all operations are conducted
in-memory and thus the amount of data you can work with is limited by available
memory. The database connections essentially remove that limitation in that you
can connect to a database of many hundreds of GB, conduct queries on it directly, and pull
back into R only what you need for analysis.

The package **`tidyr`** addresses the common problem of wanting to reshape your data for plotting and use by different R functions. Sometimes we want data sets where we have one row per measurement. Sometimes we want a data frame where each measurement type has its own column, and rows are instead more aggregated groups - like plots or aquaria. Moving back and forth between these formats is nontrivial, and **`tidyr`** gives you tools for this and more sophisticated  data manipulation.

To learn more about **`dplyr`** and **`tidyr`** after the workshop, you may want to check out this
[handy data transformation with **`dplyr`** cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) and this [one about **`tidyr`**](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf).

We'll read in our data using the `read_csv()` function, from the tidyverse package **`readr`**, instead of `read.csv()`, the base function for reading in data. The data we are going to be using today should already be in your R_DAVIS_2022 project in the folder `data`. 

```{r,results = 'hide', purl = FALSE}
yield_df <- read.csv("input_data/tomato_grafting_yield_spad.csv", header = TRUE)

## inspect the data
str(yield_df)


# head of the data
head(yield_df)
```

Notice that the class of the data is now `tbl_df`
This is referred to as a "tibble".
Tibbles are almost identical to R's standard data frames, but they tweak some of the old behaviors of data frames. For our purposes the only differences between data frames
and tibbles are that:

1. When you print a tibble, R displays the data type of each column under its name; it prints only the first few rows of data and only as many columns as fit
on one screen.
2. Columns of class `character` are never automatically converted into factors.

## Selecting columns and filtering rows

We're going to learn some of the most common **`dplyr`** functions: `select()`,
`filter()`, `mutate()`, `group_by()`, `summarize()`, and `join`. To select columns of a
data frame, use `select()`. The first argument to this function is the data
frame (`surveys`), and the subsequent arguments are the **columns** to keep.

```{r, results = 'hide', purl = FALSE}
head(select(yield_df, plantID, sampling_date))
```
We can also use pipe function to make it more clear. 
Pipes let you take
the output of one function and send it directly to the next, which is useful
when you need to do many things to the same dataset.  Pipes in R look like
`%>%` and are made available via the **`magrittr`** package, installed automatically
with **`dplyr`**. If you use RStudio, you can type the pipe with <kbd>Ctrl</kbd>
+ <kbd>Shift</kbd> + <kbd>M</kbd> if you have a PC or <kbd>Cmd</kbd> + 
<kbd>Shift</kbd> + <kbd>M</kbd> if you have a Mac.

```{r}
library(tidyverse)
yield_df %>% select(plantID, sampling_date) %>%
  head()
```


To choose **rows** based on a specific criteria, use `filter()`:

```{r, purl = FALSE}
yield_df %>% filter(sampling_date=="6/15/18") %>%
  head()
```

`select` is used for **rows** and `filter` is used for **columns**.


What if you want to select and filter at the same time? 
Let say we want to select select plantID, sampling date, and filter marketable yield greater than 50.




```{r, purl = FALSE}
yield_df %>% 
  select(plantID, marketable_yield_kg, sampling_date) %>%
  filter(marketable_yield_kg > 50) %>%
  head()
```

In the above code, we use the pipe to send the `yield_df` dataset first through
`select()` to select the three columns of interest, then we use `filter()` to filter out rows that is greater tan 50. Since `%>%` takes
the object on its left and passes it as the first argument to the function on
its right, we don't need to explicitly include the data frame as an argument
to the `filter()` and `select()` functions any more.

Some may find it helpful to read the pipe like the word "then". For instance,
in the above example, we took the data frame `yield_df`, *then* we `filter`ed
for rows with `marketable_yield_kg > 50`, *then* we `select`ed columns `plantID`, `marketable_yield_kg`,
and `sampling_date`. The **`dplyr`** functions by themselves are somewhat simple,
but by combining them into linear workflows with the pipe, we can accomplish
more complex manipulations of data frames.

If we want to create a new object with this smaller version of the data, we
can assign it a new name:

```{r, purl = FALSE}
yield_g_50 <- yield_df %>% 
  select(plantID, marketable_yield_kg, sampling_date) %>%
  filter(marketable_yield_kg > 50)


head(yield_g_50)
```

Note that the final data frame is the leftmost part of this expression.

<div class = "blue">
### Challenge 
Can you selec the samples with marketable_yield greater than 50 for the sampled collected in june but not july? 

<details>
<summary>ANSWER</summary>
```{r, eval=FALSE, purl=FALSE}

yield_g_50_june <- yield_df %>% 
  select(plantID, marketable_yield_kg, sampling_date) %>%
  filter(marketable_yield_kg > 50 & sampling_date=="6/15/18") %>%
  head()

# what about negative selection


yield_g_50_m2 <- yield_df %>% 
  select(plantID, marketable_yield_kg, sampling_date) %>%
  filter(marketable_yield_kg > 50 & sampling_date!="july-15-2018") %>%
  head()
```
</details>
</div>
<br>

## Mutate

Frequently you'll want to create new columns based on the values in existing
columns, for example to do unit conversions, or to find the ratio of values in two
columns. For this we'll use `mutate()`.

To create a new column of weight in kg:

```{r, purl = FALSE}
yield_df %>%
  mutate(marketable_yield_gram = marketable_yield_kg * 1000) %>%
  head()
```

You can also create a second new column based on the first new column within the same call of `mutate()`:

```{r, purl = FALSE}

yield_df %>%
  mutate(marketable_yield_gram = marketable_yield_kg * 1000, 
         marketable_yield_lbs = marketable_yield_kg * 2.2) %>%
  head()
```

If this runs off your screen and you just want to see the first few rows, you
can use a pipe to view the `head()` of the data. (Pipes work with non-**`dplyr`**
functions, too, as long as the **`dplyr`** or `magrittr` package is loaded).

```{r, purl = FALSE}

yield_df %>%
  mutate(marketable_yield_gram = marketable_yield_kg * 1000, 
         marketable_yield_lbs = marketable_yield_kg * 2.2) %>%
  head()
```
How to deal with NA in data?
Although the example data set that we are working here doesnot have NA. Lets  modify the dataframe and work with it. For now you can just run the following code.
```{r}
yield_wit_NA_df <- yield_df %>%
  mutate(raw_yield = ifelse(marketable_yield_kg < 20, NA, marketable_yield_kg)) %>%
  head()
```


The first few rows of the output are full of `NA`s, so if we wanted to remove
those we could insert a `filter()` in the chain:

```{r, purl = FALSE}
yield_wit_NA_df %>%
  filter(!is.na(raw_yield)) %>%
  mutate(marketable_yield_gram = marketable_yield_kg * 1000) %>%
  head()
```

`is.na()` is a function that determines whether something is an `NA`. The `!`
symbol negates the result, so we're asking for every row where weight *is not* an `NA`.

<div class = "blue">
### Challenge

Create a new data frame from the `yield_wit_NA_df` data that meets the following
criteria: contains only the `plantID`, `sampling_date` columns, and a new column called
`marketable_yield_lbs` containing values of marketable yield in pound (lbs). Note: 1kg ~ 2.2lbs
In this `marketable_yield_lbs` column, there are no `NA`s and all values are less
than 100lbs and belong to july sampling. Name this data frame `yield_july_lbs_df`.

**Hint**: think about how the commands should be ordered to produce this data frame!

<details>
<summary>ANSWER</summary>
```{r, eval=FALSE, purl=FALSE}
yield_july_lbs_df <- yield_wit_NA_df %>%
    filter(!is.na(raw_yield)) %>%
    filter(sampling_date=="july-15-2018") %>%
    mutate(marketable_yield_lbs = marketable_yield_kg * 2.2) %>%
    filter(marketable_yield_lbs > 100 ) %>%
    select(plantID, sampling_date, marketable_yield_lbs)
```
</details>
</div>
<br>

## Group by and summarize

Many data analysis tasks can be approached using the *split-apply-combine*
paradigm: split the data into groups, apply some analysis to each group, and
then combine the results. **`dplyr`** makes this very easy through the use of the
`group_by()` function.

`group_by()` is often used together with `summarize()`, which collapses each
group into a single-row summary of that group.  `group_by()` takes as arguments
the column names that contain the **categorical** variables for which you want
to calculate the summary statistics. So to compute the mean `weight` by sex:

```{r, purl = FALSE}
yield_df %>%
  group_by(sampling_date) %>%
  summarize(mean_weight = mean(marketable_yield_kg, na.rm = TRUE))
```

You may also have noticed that the output from these calls doesn't run off the
screen anymore. It's one of the advantages of `tbl_df` over data frame.

## Join
Often we have multiple table to work with, and in dplyr we can combine different related table using joins. 
Lets bring in our metadata file,  join with the yiled data. This will allow us to answer more interesting meaningful question regarding tomato yield across various rootstocks that we studied in this work.

```{r}
meta_df <- read.csv("input_data/tomato_grafting_metadata.csv", header = TRUE)
str(meta_df)

# merge metadata with yield data
yield_with_meata_df <- merge(yield_df, meta_df, by="plantID")

head(yield_with_meata_df)
```

ADD MERGE AND JOINS PICTURE HERE!!!


You can also group by multiple columns:

```{r, purl = FALSE}

yield_with_meata_df %>%
  group_by(rootstock, sampling_date) %>%
  summarize(mean_weight = mean(marketable_yield_kg, na.rm = TRUE))
```

Here we are getting average marketable_yield_kg by rootstocks and two sampling dates.

Once the data are grouped, you can also summarize multiple variables at the same
time (and not necessarily on the same variable). For instance, we could add a
column indicating the mean spad for each rootstock:

```{r, purl = FALSE}
yield_with_meata_df %>%
  group_by(rootstock) %>%
  summarize(mean_weight = mean(marketable_yield_kg),
            mean_spad = mean(spad_value))
```



<div class = "blue">
### Challenge

1. Find  maximum yiled by rootstocks in each sampling date Arrange the table by smapling date by in descending date, i.e july first, then june. 

2. Try out a new function, `count()`. Group the data by `rootstock` and pipe the grouped data into the `count()` function. How could you get the same result
using `group_by()` and `summarize()`? Hint: see `?n`.

2. Are the number of sample per rootstocks same for june and july?

<details>
<summary>ANSWER</summary>
```{r, purl=FALSE}
## Answer 1
yield_with_meata_df %>%
  group_by(rootstock, sampling_date) %>%
  summarize(max_yiled = max(marketable_yield_kg)) %>%
  arrange(desc(sampling_date))

## Answer 2
yield_with_meata_df %>%
  group_by(rootstock) %>%
  count()

## Answer 3
yield_with_meata_df %>%
  group_by(rootstock, sampling_date) %>%
  count()

```
</details>
</div>
<br>



